{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file to inspect the contents\n",
    "file_path = 'budjet.xlsx'\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Display sheet names to understand the structure of the file\n",
    "excel_data.sheet_names\n",
    "\n",
    "# Load the data from the 'budjet' sheet\n",
    "df = excel_data.parse('budjet')\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "df.head()\n",
    "\n",
    "# Save the cleaned dataset to a CSV file\n",
    "csv_file_path = 'budget_data.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>16.59</td>\n",
       "      <td>12154.99</td>\n",
       "      <td>110.25</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>18.43</td>\n",
       "      <td>16255.03</td>\n",
       "      <td>127.50</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>17.48</td>\n",
       "      <td>9208.34</td>\n",
       "      <td>95.96</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>18.16</td>\n",
       "      <td>15025.66</td>\n",
       "      <td>122.58</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model   MAE      MSE   RMSE    R2  MAPE\n",
       "0      Random Forest 16.59 12154.99 110.25 -0.32  2.59\n",
       "1      Decision Tree 18.43 16255.03 127.50 -0.77  2.27\n",
       "2  Linear Regression 17.48  9208.34  95.96 -0.00  3.68\n",
       "3            XGBoost 18.16 15025.66 122.58 -0.63  2.70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Load your dataset (update the path accordingly if needed)\n",
    "file_path = 'budjet.xlsx'\n",
    "budjet_data = pd.read_excel(file_path, sheet_name='budjet')\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Convert the date into useful features\n",
    "budjet_data['date'] = pd.to_datetime(budjet_data['date'])\n",
    "budjet_data['year'] = budjet_data['date'].dt.year\n",
    "budjet_data['month'] = budjet_data['date'].dt.month\n",
    "budjet_data['day'] = budjet_data['date'].dt.day\n",
    "budjet_data['day_of_week'] = budjet_data['date'].dt.dayofweek\n",
    "\n",
    "# Encode the 'category' column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "budjet_data['category_encoded'] = label_encoder.fit_transform(budjet_data['category'])\n",
    "\n",
    "# Drop the original 'date' and 'category' columns\n",
    "budjet_data_cleaned = budjet_data.drop(columns=['date', 'category'])\n",
    "\n",
    "# Step 2: Splitting the Data into Training and Testing Sets\n",
    "X = budjet_data_cleaned.drop(columns=['amount'])\n",
    "y = budjet_data_cleaned['amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Define a dictionary of models to evaluate\n",
    "models_dict = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Step 4: Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Step 5: Train and evaluate each model, collecting all metrics\n",
    "metrics_results = []\n",
    "\n",
    "for model_name, model in models_dict.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    # Append results to the list as a dictionary\n",
    "    metrics_results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"MAE\": metrics[\"MAE\"],\n",
    "        \"MSE\": metrics[\"MSE\"],\n",
    "        \"RMSE\": metrics[\"RMSE\"],\n",
    "        \"R2\": metrics[\"R2\"],\n",
    "        \"MAPE\": metrics[\"MAPE\"]\n",
    "    })\n",
    "\n",
    "# Step 6: Convert the results list into a DataFrame\n",
    "metrics_results_df = pd.DataFrame(metrics_results)\n",
    "\n",
    "# Step 7: Display the results\n",
    "metrics_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 8, 'min_samples_split': 16, 'n_estimators': 116}\n",
      "Best parameters for Decision Tree: {'max_depth': 8, 'min_samples_split': 12}\n",
      "Best parameters for XGBoost: {'learning_rate': np.float64(0.1009124836035503), 'max_depth': 2, 'n_estimators': 67}\n",
      "               Model   MAE      MSE   RMSE    R2  MAPE\n",
      "0      Random Forest 13.76  8796.42  93.79  0.04  2.03\n",
      "1      Decision Tree 16.08 10863.09 104.23 -0.18  2.32\n",
      "2            XGBoost 14.68  8694.74  93.25  0.06  2.58\n",
      "3  Linear Regression 17.48  9208.34  95.96 -0.00  3.68\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Load your dataset (update the path accordingly if needed)\n",
    "file_path = 'budjet.xlsx'  # replace with your actual file path\n",
    "budjet_data = pd.read_excel(file_path, sheet_name='budjet')\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "budjet_data['date'] = pd.to_datetime(budjet_data['date'])\n",
    "budjet_data['year'] = budjet_data['date'].dt.year\n",
    "budjet_data['month'] = budjet_data['date'].dt.month\n",
    "budjet_data['day'] = budjet_data['date'].dt.day\n",
    "budjet_data['day_of_week'] = budjet_data['date'].dt.dayofweek\n",
    "\n",
    "# Encode the 'category' column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "budjet_data['category_encoded'] = label_encoder.fit_transform(budjet_data['category'])\n",
    "\n",
    "# Drop the original 'date' and 'category' columns\n",
    "budjet_data_cleaned = budjet_data.drop(columns=['date', 'category'])\n",
    "\n",
    "# Step 2: Splitting the Data into Training and Testing Sets\n",
    "X = budjet_data_cleaned.drop(columns=['amount'])\n",
    "y = budjet_data_cleaned['amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Define a dictionary of models to evaluate and their hyperparameter grids\n",
    "\n",
    "param_distributions = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': randint(10, 200),\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': randint(10, 200),\n",
    "        'learning_rate': uniform(0.01, 0.5),\n",
    "        'max_depth': randint(2, 20),\n",
    "    }\n",
    "}\n",
    "\n",
    "models_dict = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Linear Regression has no hyperparameters to tune\n",
    "models_dict[\"Linear Regression\"] = LinearRegression()\n",
    "\n",
    "# Step 4: Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Step 5: Hyperparameter tuning using RandomizedSearchCV\n",
    "best_models = {}\n",
    "for model_name, model in models_dict.items():\n",
    "    if model_name in param_distributions:\n",
    "        # Perform RandomizedSearchCV for models with hyperparameters\n",
    "        random_search = RandomizedSearchCV(model, param_distributions[model_name], n_iter=20, cv=5, scoring='neg_mean_absolute_error', random_state=42, n_jobs=-1)\n",
    "        random_search.fit(X_train, y_train)\n",
    "        best_models[model_name] = random_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    else:\n",
    "        # No hyperparameters to tune for Linear Regression\n",
    "        model.fit(X_train, y_train)\n",
    "        best_models[model_name] = model\n",
    "\n",
    "# Step 6: Train and evaluate each model, collecting all metrics\n",
    "metrics_results = []\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    # Append results to the list as a dictionary\n",
    "    metrics_results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"MAE\": metrics[\"MAE\"],\n",
    "        \"MSE\": metrics[\"MSE\"],\n",
    "        \"RMSE\": metrics[\"RMSE\"],\n",
    "        \"R2\": metrics[\"R2\"],\n",
    "        \"MAPE\": metrics[\"MAPE\"]\n",
    "    })\n",
    "\n",
    "# Step 7: Convert the results list into a DataFrame\n",
    "metrics_results_df = pd.DataFrame(metrics_results)\n",
    "\n",
    "# Step 8: Display the results\n",
    "print(metrics_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 8, 'min_samples_split': 20, 'n_estimators': 150}\n",
      "Best parameters for XGBoost: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 50}\n",
      "Random Forest Performance: {'MAE': np.float64(13.765277950080094), 'MSE': np.float64(8687.114808753782), 'RMSE': np.float64(93.2046930618506), 'R2': 0.05612479232435996, 'MAPE': np.float64(2.011194809329284)}\n",
      "XGBoost Performance: {'MAE': np.float64(15.256947376087432), 'MSE': np.float64(10316.201995660605), 'RMSE': np.float64(101.56870578904018), 'R2': -0.12087931556586207, 'MAPE': np.float64(2.287674207806325)}\n",
      "           Model   MAE      MSE   RMSE    R2  MAPE\n",
      "0  Random Forest 13.77  8687.11  93.20  0.06  2.01\n",
      "1        XGBoost 15.26 10316.20 101.57 -0.12  2.29\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Load your dataset (update the path accordingly if needed)\n",
    "file_path = 'budjet.xlsx'  # replace with your actual file path\n",
    "budjet_data = pd.read_excel(file_path, sheet_name='budjet')\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "budjet_data['date'] = pd.to_datetime(budjet_data['date'])\n",
    "budjet_data['year'] = budjet_data['date'].dt.year\n",
    "budjet_data['month'] = budjet_data['date'].dt.month\n",
    "budjet_data['day'] = budjet_data['date'].dt.day\n",
    "budjet_data['day_of_week'] = budjet_data['date'].dt.dayofweek\n",
    "\n",
    "# Encode the 'category' column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "budjet_data['category_encoded'] = label_encoder.fit_transform(budjet_data['category'])\n",
    "\n",
    "# Drop the original 'date' and 'category' columns\n",
    "budjet_data_cleaned = budjet_data.drop(columns=['date', 'category'])\n",
    "\n",
    "# Step 2: Splitting the Data into Training and Testing Sets\n",
    "X = budjet_data_cleaned.drop(columns=['amount'])\n",
    "y = budjet_data_cleaned['amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Define parameter grids for Random Forest and XGBoost\n",
    "\n",
    "# Random Forest hyperparameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'min_samples_split': [10, 16, 20],\n",
    "}\n",
    "\n",
    "# XGBoost hyperparameter grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 67, 100],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Step 4: GridSearchCV for hyperparameter tuning\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {rf_grid_search.best_params_}\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "print(f\"Best parameters for XGBoost: {xgb_grid_search.best_params_}\")\n",
    "\n",
    "# Step 5: Define a function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Step 6: Evaluate the optimized models\n",
    "\n",
    "# Predict with Random Forest\n",
    "rf_y_pred = best_rf_model.predict(X_test)\n",
    "rf_metrics = calculate_metrics(y_test, rf_y_pred)\n",
    "print(f\"Random Forest Performance: {rf_metrics}\")\n",
    "\n",
    "# Predict with XGBoost\n",
    "xgb_y_pred = best_xgb_model.predict(X_test)\n",
    "xgb_metrics = calculate_metrics(y_test, xgb_y_pred)\n",
    "print(f\"XGBoost Performance: {xgb_metrics}\")\n",
    "\n",
    "# Step 7: Combine the results into a DataFrame\n",
    "metrics_results = pd.DataFrame([\n",
    "    {\"Model\": \"Random Forest\", **rf_metrics},\n",
    "    {\"Model\": \"XGBoost\", **xgb_metrics}\n",
    "])\n",
    "\n",
    "# Step 8: Display the results\n",
    "print(metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 105, 'max_depth': 9, 'min_samples_split': 13}\n",
      "Optimized Random Forest Performance: {'MAE': np.float64(13.438903151765832), 'MSE': np.float64(8905.012597056158), 'RMSE': np.float64(94.36637429220303), 'R2': 0.03244969136003051, 'MAPE': np.float64(1.9638798562496125)}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import necessary libraries\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Step 3: Load your dataset (update the path accordingly if needed)\n",
    "file_path = 'budjet.xlsx'  # replace with your actual file path\n",
    "budjet_data = pd.read_excel(file_path, sheet_name='budjet')\n",
    "\n",
    "# Step 4: Data Preprocessing\n",
    "budjet_data['date'] = pd.to_datetime(budjet_data['date'])\n",
    "budjet_data['year'] = budjet_data['date'].dt.year\n",
    "budjet_data['month'] = budjet_data['date'].dt.month\n",
    "budjet_data['day'] = budjet_data['date'].dt.day\n",
    "budjet_data['day_of_week'] = budjet_data['date'].dt.dayofweek\n",
    "\n",
    "# Encode the 'category' column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "budjet_data['category_encoded'] = label_encoder.fit_transform(budjet_data['category'])\n",
    "\n",
    "# Drop the original 'date' and 'category' columns\n",
    "budjet_data_cleaned = budjet_data.drop(columns=['date', 'category'])\n",
    "\n",
    "# Step 5: Split the Data\n",
    "X = budjet_data_cleaned.drop(columns=['amount'])\n",
    "y = budjet_data_cleaned['amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 6, 12)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 10, 30)\n",
    "\n",
    "    # Create the RandomForestRegressor with trial parameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Step 7: Optimize the objective function using Optuna\n",
    "study = optuna.create_study(direction='minimize')  # We want to minimize MAE\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Step 8: Display the best parameters and performance\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Step 9: Train the model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 10: Evaluate the optimized model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Step 11: Display the results\n",
    "metrics_results = {\n",
    "    \"MAE\": mae,\n",
    "    \"MSE\": mse,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R2\": r2,\n",
    "    \"MAPE\": mape\n",
    "}\n",
    "print(\"Optimized Random Forest Performance:\", metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 172, 'max_depth': 11, 'min_samples_split': 29}\n",
      "Optimized Random Forest Performance: {'MAE': np.float64(3.073095919018062), 'MSE': np.float64(17.003522049173636), 'RMSE': np.float64(4.123532714696664), 'R2': 0.16535618446837252, 'MAPE': np.float64(0.9409262117778985)}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import necessary libraries\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Step 3: Load your dataset (update the path accordingly if needed)\n",
    "file_path = 'budjet.xlsx'  # replace with your actual file path\n",
    "budjet_data = pd.read_excel(file_path, sheet_name='budjet')\n",
    "\n",
    "# Step 4: Data Preprocessing\n",
    "budjet_data['date'] = pd.to_datetime(budjet_data['date'])\n",
    "budjet_data['year'] = budjet_data['date'].dt.year\n",
    "budjet_data['month'] = budjet_data['date'].dt.month\n",
    "budjet_data['day'] = budjet_data['date'].dt.day\n",
    "budjet_data['day_of_week'] = budjet_data['date'].dt.dayofweek\n",
    "\n",
    "# Encode the 'category' column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "budjet_data['category_encoded'] = label_encoder.fit_transform(budjet_data['category'])\n",
    "\n",
    "# Drop the original 'date' and 'category' columns\n",
    "budjet_data_cleaned = budjet_data.drop(columns=['date', 'category'])\n",
    "\n",
    "# Step 5: Remove Outliers Using IQR\n",
    "Q1 = budjet_data_cleaned.quantile(0.25)\n",
    "Q3 = budjet_data_cleaned.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Remove outliers outside 1.5*IQR range\n",
    "budjet_data_cleaned = budjet_data_cleaned[~((budjet_data_cleaned < (Q1 - 1.5 * IQR)) | (budjet_data_cleaned > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Step 6: Split the data into features (X) and target (y)\n",
    "X = budjet_data_cleaned.drop(columns=['amount'])\n",
    "y = budjet_data_cleaned['amount']\n",
    "\n",
    "# Step 7: Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 6, 12)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 10, 30)\n",
    "\n",
    "    # Create the RandomForestRegressor with trial parameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Step 9: Optimize the objective function using Optuna\n",
    "study = optuna.create_study(direction='minimize')  # We want to minimize MAE\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Step 10: Display the best parameters and performance\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Step 11: Train the model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 12: Evaluate the optimized model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Step 13: Display the results\n",
    "metrics_results = {\n",
    "    \"MAE\": mae,\n",
    "    \"MSE\": mse,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R2\": r2,\n",
    "    \"MAPE\": mape\n",
    "}\n",
    "print(\"Optimized Random Forest Performance:\", metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 100, 'max_depth': 11, 'min_samples_split': 20}\n",
      "   MAE   MSE  RMSE   R2  MAPE\n",
      "0 3.07 17.15  4.14 0.16  0.94\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import necessary libraries\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna.logging\n",
    "\n",
    "# Suppress Optuna logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Step 3: Load your dataset (update the path accordingly if needed)\n",
    "file_path = 'budjet.xlsx'  # replace with your actual file path\n",
    "budjet_data = pd.read_excel(file_path, sheet_name='budjet')\n",
    "\n",
    "# Step 4: Data Preprocessing\n",
    "budjet_data['date'] = pd.to_datetime(budjet_data['date'])\n",
    "budjet_data['year'] = budjet_data['date'].dt.year\n",
    "budjet_data['month'] = budjet_data['date'].dt.month\n",
    "budjet_data['day'] = budjet_data['date'].dt.day\n",
    "budjet_data['day_of_week'] = budjet_data['date'].dt.dayofweek\n",
    "\n",
    "# Encode the 'category' column using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "budjet_data['category_encoded'] = label_encoder.fit_transform(budjet_data['category'])\n",
    "\n",
    "# Drop the original 'date' and 'category' columns\n",
    "budjet_data_cleaned = budjet_data.drop(columns=['date', 'category'])\n",
    "\n",
    "# Step 5: Remove Outliers Using IQR\n",
    "Q1 = budjet_data_cleaned.quantile(0.25)\n",
    "Q3 = budjet_data_cleaned.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Remove outliers outside 1.5*IQR range\n",
    "budjet_data_cleaned = budjet_data_cleaned[~((budjet_data_cleaned < (Q1 - 1.5 * IQR)) | (budjet_data_cleaned > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Step 6: Split the data into features (X) and target (y)\n",
    "X = budjet_data_cleaned.drop(columns=['amount'])\n",
    "y = budjet_data_cleaned['amount']\n",
    "\n",
    "# Step 7: Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 6, 12)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 10, 30)\n",
    "\n",
    "    # Create the RandomForestRegressor with trial parameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Step 9: Optimize the objective function using Optuna\n",
    "study = optuna.create_study(direction='minimize')  # We want to minimize MAE\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Step 10: Get the best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Step 11: Train the model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 12: Evaluate the optimized model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Step 13: Store the results in a DataFrame\n",
    "metrics_results = pd.DataFrame([{\n",
    "    \"MAE\": mae,\n",
    "    \"MSE\": mse,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R2\": r2,\n",
    "    \"MAPE\": mape\n",
    "}])\n",
    "\n",
    "# Step 14: Print the best hyperparameters and the results as a DataFrame\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
